{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    # Retrieve the API key from the environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # Check if the API key is present\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key not found in the .env file\")\n",
    "    \n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=get_api_key()\n",
    "client = OpenAI(api_key=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFileOpenAI(location):\n",
    "    with open(location, 'rb') as file:\n",
    "        response = client.files.create(file=file, purpose='assistants')\n",
    "    print(response)\n",
    "    return response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\Users\\faiza\\Videos\\Bayes\\GPT\\Assistant_OpenAI\n",
      "Additional Location: file/DemoDFL.pptx\n",
      "New Path: c:\\Users\\faiza\\Videos\\Bayes\\GPT\\Assistant_OpenAI\\file/DemoDFL.pptx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Additional location to add\n",
    "additional_location = \"data/DemoDFL.pptx\"\n",
    "\n",
    "# Combine paths using os.path.join()\n",
    "loc = os.path.join(base_dir, additional_location)\n",
    "\n",
    "# Display the result\n",
    "print(\"Base Directory:\", base_dir)\n",
    "print(\"Additional Location:\", additional_location)\n",
    "print(\"New Path:\", loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-DmCJ5aXW1QY7yVueYG0K9COw', bytes=934888, created_at=1704824894, filename='Research_2.pdf', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file-DmCJ5aXW1QY7yVueYG0K9COw'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id=saveFileOpenAI(location=loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_assistants():\n",
    "    assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are knowledge assistant,Use your knowledge base to best respond to user queries\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    file_ids=[file_id]\n",
    ")\n",
    "    print(assistant)\n",
    "    return assistant.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_TU3IMSi6vvHUzwzACFNiRO94', created_at=1704825821, description=None, file_ids=['file-DmCJ5aXW1QY7yVueYG0K9COw'], instructions='You are knowledge assistant,Use your knowledge base to best respond to user queries', metadata={}, model='gpt-4-1106-preview', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'asst_TU3IMSi6vvHUzwzACFNiRO94'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistan_id=start_assistants()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_tread(propmt):\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": propmt,\n",
    "        }\n",
    "    ]\n",
    "    thread = client.beta.threads.create(messages=messages\n",
    "    )\n",
    "    print(thread)\n",
    "    return thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_VpsnT0aJlyIXgeURB6feaUNu', created_at=1704826270, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "question=\"Who is the author in research paper and what is the title of the research paper\"\n",
    "tread_id=start_tread(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistance(thread_id,assistant_id):\n",
    "    run = client.beta.threads.runs.create(\n",
    "    thread_id=thread_id,\n",
    "    assistant_id=assistant_id,\n",
    "    )\n",
    "    print(run)\n",
    "    return run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_GoAbG7wJqvyRpyU4uBqISKSt', assistant_id='asst_TU3IMSi6vvHUzwzACFNiRO94', cancelled_at=None, completed_at=None, created_at=1704826568, expires_at=1704827168, failed_at=None, file_ids=['file-DmCJ5aXW1QY7yVueYG0K9COw'], instructions='You are knowledge assistant,Use your knowledge base to best respond to user queries', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_VpsnT0aJlyIXgeURB6feaUNu', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "run_id=run_assistance(tread_id,assistan_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkrunstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRunStatus(thread_id,run_id):\n",
    "    run=client.beta.threads.runs.retrieve(run_id=run_id,thread_id=thread_id)\n",
    "    return run.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkRunStatus(tread_id,run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrive Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveThread(thread_id):\n",
    "    thread_message=client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    list_message=thread_message.data\n",
    "    print(thread_message)\n",
    "    assistance_message=list_message[0]\n",
    "    reference=assistance_message.content[0].text.annotations[0].file_citation.quote\n",
    "    messsage_text=assistance_message.content[0].text.value\n",
    "\n",
    "\n",
    "    return messsage_text,reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_2agnPOoAcF4o6sHIMyMzZ3Ej', assistant_id='asst_TU3IMSi6vvHUzwzACFNiRO94', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=182, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-DmCJ5aXW1QY7yVueYG0K9COw', quote='Scalability and Reliability in Semi-Decentralized\\nFederated Learning With Blockchain: Trust\\nPenalization and Asynchronous Functionality\\nline 1: 1st Given Name Surname \\nline 2: dept. name of organization\\n(of Affiliation) \\nline 3: name of organization \\n(of Affiliation) \\nline 4: City Country\\nline 5: email address or ORCID'), start_index=172, text='【7†source】', type='file_citation'), TextAnnotationFileCitation(end_index=401, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-DmCJ5aXW1QY7yVueYG0K9COw', quote='1st Given Name Surname \\nline 2: dept. name of organization\\n(of Affiliation) \\nline 3: name of organization \\n(of Affiliation) \\nline 4: City Country\\nline 5: email address or ORCID \\n\\n\\nline 1: 2nd Given Name Surname\\nline 2: dept. name of organization\\n(of Affiliation) \\nline 3: name of organization \\n(of Affiliation) \\nline 4: City Country\\nline 5: email address or ORCID \\n\\n\\nline 1: 3rd Given Name Surname\\nline 2: dept. name of organization \\n(of Affiliation) \\nline 3: name of organization \\n(of Affiliation) \\nline 4: City Country\\nline 5: email address or ORCID\\n\\n\\nline 1: 4th Given Name Surname\\nline 2: dept. name of organization \\n(of Affiliation) \\nline 3: name of organization \\n(of Affiliation) \\nline 4: City Country\\nline 5: email address or ORCID \\n\\n\\nline 1: 5th Given Name Surname\\nline 2: dept. name of organization\\n(of Affiliation) \\nline 3: name of organization \\n(of Affiliation) \\nline 4: City Country\\nline 5: email address or ORCID \\n\\n\\nline 1: 6th Given Name Surname'), start_index=391, text='【8†source】', type='file_citation')], value='The title of the research paper is \"Scalability and Reliability in Semi-Decentralized Federated Learning With Blockchain: Trust Penalization and Asynchronous Functionality\"【7†source】.\\n\\nThe authors of the research paper are listed as follows:\\n- 1st Given Name Surname\\n- 2nd Given Name Surname\\n- 3rd Given Name Surname\\n- 4th Given Name Surname\\n- 5th Given Name Surname\\n- 6th Given Name Surname【8†source】.\\n\\nUnfortunately, the specific names of the authors are not provided in the quotes extracted from the document. The placeholders \"Given Name\" and \"Surname\" are used instead of the real names. To get the actual names of the authors, I would need to access the full document content at the section listing author names. Would you like me to do that?'), type='text')], created_at=1704826575, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_GoAbG7wJqvyRpyU4uBqISKSt', thread_id='thread_VpsnT0aJlyIXgeURB6feaUNu'), ThreadMessage(id='msg_QUhZUhs2FNcIB8g9JgjWOOuV', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Who is the author in research paper and what is the title of the research paper'), type='text')], created_at=1704826270, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_VpsnT0aJlyIXgeURB6feaUNu')], object='list', first_id='msg_2agnPOoAcF4o6sHIMyMzZ3Ej', last_id='msg_QUhZUhs2FNcIB8g9JgjWOOuV', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "mess_text,refer=retrieveThread(thread_id=tread_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the research paper is \"Scalability and Reliability in Semi-Decentralized Federated Learning With Blockchain: Trust Penalization and Asynchronous Functionality\"【7†source】.\n",
      "\n",
      "The authors of the research paper are listed as follows:\n",
      "- 1st Given Name Surname\n",
      "- 2nd Given Name Surname\n",
      "- 3rd Given Name Surname\n",
      "- 4th Given Name Surname\n",
      "- 5th Given Name Surname\n",
      "- 6th Given Name Surname【8†source】.\n",
      "\n",
      "Unfortunately, the specific names of the authors are not provided in the quotes extracted from the document. The placeholders \"Given Name\" and \"Surname\" are used instead of the real names. To get the actual names of the authors, I would need to access the full document content at the section listing author names. Would you like me to do that?\n"
     ]
    }
   ],
   "source": [
    "print(mess_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
