{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement open (from versions: none)\n",
      "ERROR: No matching distribution found for open\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade open ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client= OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "file = client.files.create(\n",
    "  file=open(\"../data/DemoDFL.pptx\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:Create an Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the file to the assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a machine learning researcher. Use your knowledge base to best respond to user queries.\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\": \"retrieval\"}],\n",
    "  file_ids=[file.id]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create a Thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Add a Message to a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what are components of bdcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Run the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Check the Run status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_Swshke6SsgkgEoUu57cUq6Vi', assistant_id='asst_GeINFtTb9Ylo2dK57jcp9ZPy', cancelled_at=None, completed_at=1704821957, created_at=1704821947, expires_at=None, failed_at=None, file_ids=['file-8yJBCNzChYpEz1UU4UWFjFuO'], instructions='You are a machine learning researcher. Use your knowledge base to best respond to user queries.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1704821947, status='completed', thread_id='thread_fOvq7venhblvFhjjWiptvOaT', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Display the Assistant's Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:what are components of bdcp\n",
      "assistant:The components of the Bayes Decentralized Computation Protocol (BDCP) are as follows:\n",
      "\n",
      "1. Public Blockchain\n",
      "2. Bayes network communication protocol (MQTT)\n",
      "3. Data storage and management (IPFS)\n",
      "4. Machine learning training server (DFL)\n",
      "5. Bayes network nodes management (BayesStack)【7†source】.\n"
     ]
    }
   ],
   "source": [
    "for message in reversed(messages.data):\n",
    "    print(message.role +\":\"+message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
